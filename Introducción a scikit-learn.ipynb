{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recorrido por las posibilidades de la librería ([guías de usuario](http://scikit-learn.org/stable/user_guide.html))\n",
    "* Familizarización con la documentación ([API](http://scikit-learn.org/stable/modules/classes.html))\n",
    "* **Tarea**: Implementación de un flujo de trabajo sencillo para regresión (parecido al [tutorial básico](http://scikit-learn.org/stable/tutorial/basic/tutorial.html))\n",
    "\n",
    "Estas notas pueden encontrarse en el repositorio https://github.com/matiasbattocchia/clases-aprendizaje-automatico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerrequisitos\n",
    "\n",
    "http://cs231n.github.io/python-numpy-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilidad\n",
    "\n",
    "* Aprendizaje supervisado\n",
    "    * Clasificación\n",
    "    * Regresión\n",
    "* Aprendizaje no supervisado\n",
    "* ~~Aprendizaje por refuerzos~~\n",
    "\n",
    "Redes neuronales: solo perceptrón multicapa y *restricted Boltzmann machine*.\n",
    "\n",
    "### Extensiones\n",
    "\n",
    "http://scikit-learn.org/stable/related_projects.html\n",
    "\n",
    "* Pandas\n",
    "* Más algoritmos\n",
    "* **Automatización**\n",
    "* Dominios específicos\n",
    "    * Visión computarizada (imágenes)\n",
    "    * Procesamiento del lenguaje (texto)\n",
    "    * Medicina, astronomía, geografía...\n",
    "\n",
    "\n",
    "### Datos\n",
    "\n",
    "`scikit-learn` consume **datos** con forma de matriz o arreglo bidimensional, de dimensión `(n_muestras, n_atributos)` — es como imaginamos normalmente a los datos, dispuestos en una tabla donde las **columnas** son los atributos y hay tantas muestras como **filas**.\n",
    "\n",
    "Convencionalmente en la documentación la varible *`X`* se utiliza para los **atributos** propiamente dichos, y la variable *`y`* para los **objetivos**. Cuando el objetivo es uno solo, *`y`* suele tomar la forma de arreglo unidimensional de dimensión `(n_muestras,)`. \n",
    "\n",
    "### Objetos\n",
    "\n",
    "En `scikit-learn` hay dos tipos fundamentales de objetos:\n",
    "\n",
    "* Los **transformadores**, que implementan los métodos\n",
    "    * `fit(X, y)` y\n",
    "    * `transform(X)`,\n",
    "\n",
    "* y los **estimadores**, que implementan\n",
    "    * `fit(X, y)`,\n",
    "    * `predict(X)`.\n",
    "\n",
    "### Aprendizaje supervisado\n",
    "    \n",
    "- 1.1. **Generalized Linear Models**\n",
    "- 1.2. Linear and Quadratic Discriminant Analysis\n",
    "- 1.3. Kernel ridge regression\n",
    "- 1.4. **Support Vector Machines**\n",
    "- 1.5. Stochastic Gradient Descent\n",
    "- 1.6. **Nearest Neighbors**\n",
    "- 1.7. Gaussian Processes\n",
    "- 1.8. Cross decomposition\n",
    "- 1.9. **Naive Bayes**\n",
    "- 1.10. **Decision Trees**\n",
    "- 1.11. Ensemble methods\n",
    "- 1.12. Multiclass and multilabel algorithms\n",
    "- 1.13. Feature selection\n",
    "- 1.14. Semi-Supervised\n",
    "- 1.15. Isotonic regression\n",
    "- 1.16. Probability calibration\n",
    "- 1.17. Neural network models (supervised)\n",
    "\n",
    "### Aprendizaje no supervisado\n",
    "\n",
    "- 2.1. Gaussian mixture models\n",
    "- 2.2. Manifold learning\n",
    "- 2.3. **Clustering**\n",
    "- 2.4. Biclustering\n",
    "- 2.5. **Decomposing signals in components** (matrix factorization problems)\n",
    "- 2.6. Covariance estimation\n",
    "- 2.7. Novelty and Outlier Detection\n",
    "- 2.8. Density Estimation\n",
    "- 2.9. Neural network models (unsupervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flujo de trabajo\n",
    "\n",
    "<img src='https://docs.google.com/drawings/d/1HJH4Al7gkcIKOr21w-ciZwAFZad6CsU_YKdeAiHHolA/pub?w=960&h=720' alt=\"flujo de trabajo\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos de plantas de iris\n",
    "\n",
    "*Conjunto de datos usado en gran parte de los ejemplos de estas notas*.\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/4/41/Iris_versicolor_3.jpg' alt=\"flor de iris\" style=\"width: 400px;\"/>\n",
    "\n",
    "**Cantidad de instancias**: 150\n",
    "   \t\n",
    "**Atributos** (4)\n",
    "    1. Largo del sépalo [cm]\n",
    "    2. Ancho del sépalo [cm]\n",
    "    3. Largo del pétalo [cm]\n",
    "    4. Ancho del pétalo [cm]\n",
    "    \n",
    "**Objetivos** (1)\n",
    "    5. Clase\n",
    "        - Setosa\n",
    "        - Versicolour\n",
    "        - Virginica\n",
    "\n",
    "**Valores ausentes**: No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: datos    (150, 4)\n",
      "y: objetivo (150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "print('X: datos   ', X.shape)\n",
    "print('y: objetivo', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\\*\n",
    "\n",
    "Integrando [Pandas](http://pandas.pydata.org/pandas-docs/stable) con `scikit-learn` usando el paquete [`sklearn-pandas`](https://github.com/pandas-dev/sklearn-pandas).\n",
    "\n",
    "```\n",
    "# pip install sklearn-pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hijos</th>\n",
       "      <th>mascota</th>\n",
       "      <th>salario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>gato</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>perro</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>perro</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>pez</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hijos mascota  salario\n",
       "0    4.0    gato     90.0\n",
       "1    6.0   perro     24.0\n",
       "2    3.0   perro     44.0\n",
       "3    3.0     pez     27.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.preprocessing\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "data = pd.DataFrame({'mascota': ['gato', 'perro', 'perro', 'pez'],\n",
    "                     'hijos':   [ 4.,  6,  3,  3],\n",
    "                     'salario': [90., 24, 44, 27]})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mascota_gato</th>\n",
       "      <th>mascota_perro</th>\n",
       "      <th>mascota_pez</th>\n",
       "      <th>hijos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.632993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.816497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mascota_gato  mascota_perro  mascota_pez     hijos\n",
       "0           1.0            0.0          0.0  0.000000\n",
       "1           0.0            1.0          0.0  1.632993\n",
       "2           0.0            1.0          0.0 -0.816497\n",
       "3           0.0            0.0          1.0 -0.816497"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = DataFrameMapper([\n",
    "    ('mascota', sklearn.preprocessing.LabelBinarizer()),\n",
    "    (['hijos'], sklearn.preprocessing.StandardScaler())\n",
    "], df_out=True)\n",
    "\n",
    "mapper.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: En cierta forma `DataFrameMapper` sustituye a [`FeatureUnion`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de datos\n",
    "\n",
    "https://en.wikipedia.org/wiki/Data_cleansing\n",
    "\n",
    "* Cardinalidad\n",
    "* Rango\n",
    "* Desviación\n",
    "* Tipo\n",
    "    * Booleano\n",
    "    * Numéro (separadores)\n",
    "    * Texto\n",
    "        * espacios (*trimming*)\n",
    "        * tildes\n",
    "        * casos (mayúsculas, minúsculas)\n",
    "* **Codificación** (UTF-8, etcétera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partición del conjunto de datos\n",
    "\n",
    "* Entrenamiento (50%)\n",
    "* Validación (25%) — salvo cross-validation o ausencia de hiperparámetros.\n",
    "* Prueba (25%)\n",
    "\n",
    "**Ejemplo**: [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestreo\\* — conjunto desbalanceado\n",
    "\n",
    "El *entrenamiento* y la *validación* de estimadores suele requerir conjuntos de datos **balanceados**; no así la *prueba* de los mismos ya que deben enfrentar datos reales del problema (**desbalanceados**).\n",
    "\n",
    "`scikit-learn` apenas provee algoritmos de muestro, podemos usar la extensión [`imbalanced-learn`](http://contrib.scikit-learn.org/imbalanced-learn/index.html) que implementa varios.\n",
    "\n",
    "    # pip install imbalanced-learn\n",
    "\n",
    "`imbalanced-learn` aporta objetos del tipo **muestreador** (*sampler*) que implementan los métodos\n",
    "* `fit(X, y)` y\n",
    "* `sample(X, y)`.\n",
    "\n",
    "Algunos algoritmos:\n",
    "* Under-sampling\n",
    "  * ClusterCentroids\n",
    "  * RandomUnderSampler\n",
    "* Over-sampling\n",
    "  * SMOTE\n",
    "  * RandomOverSampler\n",
    "  \n",
    "**Nota**: `imbalanced-learn` re-implementa la clase [`Pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.htm) para que admita muestreadores.\n",
    "\n",
    "**Ejemplo**: [`RandomUnderSampler`](http://contrib.scikit-learn.org/imbalanced-learn/generated/imblearn.under_sampling.RandomUnderSampler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# generación de un conjunto de datos\n",
    "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.1, 0.9],\n",
    "                           n_informative=3, n_redundant=1, flip_y=0,\n",
    "                           n_features=20, n_clusters_per_class=1,\n",
    "                           n_samples=200, random_state=10)\n",
    "\n",
    "# aplicación de random under-sampling\n",
    "rus = RandomUnderSampler()\n",
    "X_resampled, y_resampled = rus.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Preprocesamiento de atributos\n",
    "\n",
    "- 4.1. Pipeline and FeatureUnion: combining estimators\n",
    "- 4.2. Feature extraction\n",
    "- 4.3. Preprocessing data\n",
    "- 4.4. Unsupervised dimensionality reduction\n",
    "- 4.5. Random Projection\n",
    "- 4.6. Kernel Approximation\n",
    "- 4.7. Pairwise metrics, Affinities and Kernels\n",
    "- 4.8. Transforming the prediction target (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción\n",
    "\n",
    "4.2 http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "\n",
    "* Imágenes\n",
    "* Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación\n",
    "\n",
    "4.3.1 http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling\n",
    "\n",
    "* Estandarización (`StandardScaler`) — A cada atributo le remueve su valor medio y lo escala dividiéndolo por su desviación estándar.\n",
    "  * Centrar los datos es prácticamente obligatorio (hay excepciones).\n",
    "  * Normalizar los datos solo si los atributos difieren en unidades y/u órdenes de magnitud.\n",
    "* Reajuste\n",
    "    * Rango (`MinMaxScaler`)\n",
    "    * Valor absoluto (`MaxAbsScaler`)\n",
    "\n",
    "**Ejemplo**: [`StandardScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler(with_mean=True, with_std=True)\n",
    "std.fit(X_train)\n",
    "X_train_std = std.transform(X_train)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://cs231n.github.io/assets/nn2/prepro1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3.2 http://scikit-learn.org/stable/modules/preprocessing.html#normalization\n",
    "\n",
    "* Normalización (Normalizer) — Divide vectores por su norma (afecta filas en vez de columnas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación de valores ausentes\n",
    "\n",
    "4.3.5 http://scikit-learn.org/stable/modules/preprocessing.html#imputation-of-missing-values\n",
    "\n",
    "* Descarte (tirar la muestra)\n",
    "* **Valor más común**\n",
    "* **Valor medio**\n",
    "* **Valor mediano**\n",
    "* Estimación (clasificación/regresión)\n",
    "* *Hot-deck* (el valor de la muestra más parecida)\n",
    "* Valor ausente (*NA*) como otro valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación\n",
    "\n",
    "4.3.6 http://scikit-learn.org/stable/modules/preprocessing.html#generating-polynomial-features\n",
    "\n",
    "De $(X_1, X_2)$ a $(1, X_1, X_2, X_1^2, X_1X_2, X_2^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducción de dimensionalidad\n",
    "\n",
    "4.4 http://scikit-learn.org/stable/modules/unsupervised_reduction.html\n",
    "\n",
    "* PCA — análisis de componentes principales. Estandarizar los datos antes de usar PCA.\n",
    "* Casi todos los estimadores **no supervisados** implementan el método `transform(X)`.\n",
    "* [Algunos](http://scikit-learn.org/stable/modules/lda_qda.html) estimadores **supervisados** también.\n",
    "\n",
    "**Ejemplo**: [`PCA`](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, whiten=False)\n",
    "pca.fit(X_train_std)\n",
    "X_train_pca = pca.transform(X_train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://cs231n.github.io/assets/nn2/prepro2.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección — solo aprendizaje supervisado\n",
    "\n",
    "1.13 http://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n",
    "* Umbral de varianza\n",
    "* Análisis univariado\n",
    "* Usando un estimador\n",
    "* Eliminación recursiva (también existe la agregación recursiva)\n",
    "\n",
    "**Ejemplo**: [`SelectKBest`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "kbest = SelectKBest(k=1)\n",
    "kbest.fit(X_train_std, y_train)\n",
    "X_train_kbest = kbest.transform(X_train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Selección de modelos\n",
    "\n",
    "- 3.1. Cross-validation: evaluating estimator performance\n",
    "- 3.2. Tuning the hyper-parameters of an estimator\n",
    "- 3.3. Model evaluation: quantifying the quality of predictions\n",
    "- 3.4. Model persistence\n",
    "- 3.5. Validation curves: plotting scores to evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://scikit-learn.org/stable/_static/ml_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué estimador usar para el conjunto de datos de **plantas de iris**?\n",
    "\n",
    "1. ¿Más de 50 muestras? Sí, el conjunto de datos tiene 150 (en realidad un poco menos porque hemos separado un conjunto de prueba).\n",
    "2. ¿Hay que predecir una categoría? Sí, queremos predecir a qué especie pertenece cada planta.\n",
    "3. ¿Los datos estás anotados? Sí, están anotados en tres categorías.\n",
    "4. ¿Más de 100,000 muestras? No...\n",
    "\n",
    "Nos recomiendan usar una máquina de vectores de soporte ([*support vector machine*](https://en.wikipedia.org/wiki/Support_vector_machine)) con un *kernel* lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**: [`SVC`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "estimador = SVC(kernel='linear', C=1, probability=True)\n",
    "estimador.fit(X_train_std, y_train)\n",
    "\n",
    "X_test_std = std.transform(X_test)\n",
    "\n",
    "y_pred = estimador.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `predict_proba(X)`\n",
    "\n",
    "1.6 http://scikit-learn.org/stable/modules/calibration.html\n",
    "\n",
    "When performing classification you often want not only to predict the class label, but also obtain a probability of the respective label. This probability gives you some kind of confidence on the prediction. Some models can give you poor estimates of the class probabilities and some even do not support probability prediction. The calibration module allows you to better calibrate the probabilities of a given model, or to add support for probability prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimador.predict_proba(X_test[:3]).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de objetivos — solo aprendizaje supervisado\n",
    "\n",
    "1.12 http://scikit-learn.org/stable/modules/multiclass.html\n",
    "\n",
    "* Clasificador\n",
    "    * Binario\n",
    "    * Multi\n",
    "        * Clase\n",
    "        * Etiqueta\n",
    "        * Clase-etiqueta\n",
    "    \n",
    "* Regresor\n",
    "    * Univariado\n",
    "    * Multivariado\n",
    "    \n",
    "**En `scikit-learn` todos los clasificadores aceptan varias clases**. Algunos estimadores trabajan inherentemente con múltiples objetivos y le sacan provecho a la correlación entre los mismos. Cuando no es el caso del estimador, existen diferentes estrategias para que admita múltiples objetivos:\n",
    "* *OVO* (uno-contra-uno),\n",
    "* *OVA* (uno-contra-todos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensambles — solo aprendizaje supervisado\n",
    "\n",
    "1.11 http://scikit-learn.org/stable/modules/ensemble.html\n",
    "\n",
    "Diferentes tipos de ensambles:\n",
    "* Promediadores: estimadores en paralelo, reducen la **varianza**.\n",
    "* Propulsores (*boosting*): estimadores en serie, reducen el **sesgo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo\n",
    "\n",
    "3.3 http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "Cada estimador implementa un método llamado `score(X, y)` que devuelve un puntaje del desempeño del estimador. El puntaje es calculado usando una métrica acorde a la naturaleza del estimador, por ejemplo los regresores suelen reportar **R²** mientas que los clasificadores, **efectividad**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97368421052631582"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimador.score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`Efectividad`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97368421052631582"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`Matriz de confusión`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "\n",
    "https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 15,  1],\n",
       "       [ 0,  0,  9]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`Reporte`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Setosa       1.00      1.00      1.00        13\n",
      "Versicolour       1.00      0.94      0.97        16\n",
      "  Virginica       0.90      1.00      0.95         9\n",
      "\n",
      "avg / total       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clases = ['Setosa', 'Versicolour', 'Virginica']\n",
    "print(classification_report(y_test, y_pred, target_names=clases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`F1`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
    "\n",
    "*Útil para conjuntos de datos desbalanceados*.\n",
    "\n",
    "$F_1 = 2 \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{\\mathrm{precision} + \\mathrm{recall}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97395228308462156"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_pred, average='weighted')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`Kappa de Cohen`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html)\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cohen's_kappa\n",
    "\n",
    "*Útil para conjuntos de datos desbalanceados*.\n",
    "\n",
    "$\\kappa = \\frac{p_o - p_e}{1 - p_e}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95978835978835975"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cohen_kappa_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flujo de datos\n",
    "\n",
    "![](https://docs.google.com/drawings/d/1aabA_HusMS9sjpVGhFxgYtsKyTypsLz9qd5BqqwAL-U/pub?w=1922&h=663)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "4.1 http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "Todos los objetos del flujo, excepto el último, deben ser muestreadores/**transformadores** (deben implementar el método `sample`/`transform`). El último objeto puede ser de cualquier tipo, suele ser un estimador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97368421052631582"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "flujo = make_pipeline(StandardScaler(), SVC())\n",
    "flujo.fit(X_train, y_train)\n",
    "flujo.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización: validación cruzada\n",
    "\n",
    "3.1 http://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "El conjunto de datos de validación sirve para ajustar a los **hiperparámetros** de los objetos que componen el flujo de trabajo, tanto como para la composición del flujo en sí mismo. La **validación cruzada** es útil cuando el conjunto de validación es necesario y las muestras son escasas. \n",
    "\n",
    "Se necesitan dos cosas:\n",
    "1. Una estrategia de particionamiento de los datos.\n",
    "2. Una métrica de evaluación.\n",
    "\n",
    "**Estrategias**\n",
    "* K-fold, stratified k-fold — estrategias por defecto para regresores y clasificadores respectivamente.\n",
    "* Leave one out (LOO)\n",
    "* Leave P out (LPO)\n",
    "* Shuffle & split, stratified shuffle & split\n",
    "\n",
    "<img src='https://docs.google.com/drawings/d/1EoJOIjEnVkVGYDyknO7ecsk7zUucGRMrHp8yJgpaYuQ/pub?w=826&h=405' alt=\"validación cruzada\" style=\"width: 700px;\"/>\n",
    "\n",
    "**Métricas**\n",
    "* De no especificarse ninguna, se usa el método `score(X, y)` del estimador.\n",
    "* Las métricas más comunes se pueden pasar como argumento (*string*), ver [tabla](http://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
    "* Se pueden armar [**puntuadores**](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html) a partir de cualquier métrica, tanto de la API como definidas por el usuario, y pasar como argumento (*función*).\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 promedio: 0.96 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "resultados = cross_val_score(flujo, X_train, y_train, cv=5, scoring='f1_weighted')\n",
    "\n",
    "print('F1 promedio: %0.2f (+/- %0.2f)' % (resultados.mean(), resultados.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización: búsqueda\n",
    "\n",
    "3.2 http://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hiperparámetros = {\n",
    "    'svc__kernel':('linear', 'rbf'),\n",
    "         'svc__C':[1, 10]\n",
    "}\n",
    "\n",
    "grilla = GridSearchCV(flujo, hiperparámetros)\n",
    "grilla.fit(X_train, y_train)\n",
    "    \n",
    "estimador = grilla.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación final\n",
    "\n",
    "Una vez elegido el modelo y ajustados sus hiperparámetros, si se desea los conjuntos de datos de entrenamiento y de validación pueden fusionarse en un nuevo conjunto de entrenamiento para reentrenar el modelo final usando más datos — de hecho es lo que hace `GridSearchCV` para el mejor estimador.\n",
    "\n",
    "En cambio por más seguridad que se tenga del desempeño del modelo, no es recomendable usar los datos del conjunto de prueba, es mejor usarlos para medir su desempeño y asegurarnos de que esté libre de errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = estimador.predict(X_test)\n",
    "f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistencia del modelo\n",
    "\n",
    "3.4 http://scikit-learn.org/stable/modules/model_persistence.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# persistencia\n",
    "with open('modelo.pickle', 'wb') as archivo:\n",
    "    pickle.dump(estimador, archivo)\n",
    "\n",
    "# carga\n",
    "with open('modelo.pickle', 'rb') as archivo:\n",
    "    estimador = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Boston price data set\n",
    "\n",
    "**Cantidad de instancias**: 506\n",
    "   \t\n",
    "**Atributos** (13)\n",
    "    1.  CRIM per capita crime rate by town\n",
    "    2.  ZN proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "    3.  INDUS proportion of non-retail business acres per town\n",
    "    4.  CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "    5.  NOX nitric oxides concentration (parts per 10 million)\n",
    "    6.  RM average number of rooms per dwelling\n",
    "    7.  AGE proportion of owner-occupied units built prior to 1940\n",
    "    8.  DIS weighted distances to five Boston employment centres\n",
    "    9.  RAD index of accessibility to radial highways\n",
    "    10. TAX full-value property-tax rate per 10,000 USD\n",
    "    11. PTRATIO pupil-teacher ratio by town\n",
    "    12. B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "    13. LSTAT % lower status of the population\n",
    "\n",
    "**Objetivos** (1)\n",
    "    14. MEDV Median value of owner-occupied homes in 1000’s USD\n",
    "\n",
    "**Valores ausentes**: No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: datos    (506, 13)\n",
      "y: objetivo (506,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X, y   = boston.data, boston.target\n",
    "\n",
    "print('X: datos   ', X.shape)\n",
    "print('y: objetivo', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sugerencias**:\n",
    "* 1.1 [Modelo lineal](http://scikit-learn.org/stable/modules/linear_model.html)\n",
    "  * 1.1.1. Ordinary least squares\n",
    "  * 1.1.2. Ridge regression\n",
    "  * 1.1.3. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implementar estimador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89914051165600339"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred) # mientras más cerca de 1.0, mejor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Automatización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TPOT](https://github.com/rhiever/tpot) es una herramienta de aprendizaje automático automatizado que optimiza el flujo de trabajo.\n",
    "\n",
    "    # pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBRegressor is not available and will not be used by TPOT.\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "\n",
    "tpot = TPOTRegressor(generations=3, population_size=20)\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tpot.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89914051165600339"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred) # mientras más cerca de 1.0, mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpot.export('tpot_boston_pipeline.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
